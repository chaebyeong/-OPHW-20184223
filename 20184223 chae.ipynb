{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8e7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62604866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\82107\\AppData\\Local\\Temp\\ipykernel_11100\\1417366749.py:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Colleting Samples Complete!!!\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    if faces is():\n",
    "        return None\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        file_name_path = 'C:/Users/82107/Desktop/Facial-Recognition-master/faces/'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Cropper',face)\n",
    "    else:\n",
    "        print(\"Face not Found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Colleting Samples Complete!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d152e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete!!!!!\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:/Users/82107/Desktop/Facial-Recognition-master/faces/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "\n",
    "print(\"Model Training Complete!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bf6024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82107\\AppData\\Local\\Temp\\ipykernel_11100\\2535859505.py:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is():\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:/Users/82107/Desktop/Facial-Recognition-master/faces/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "\n",
    "print(\"Model Training Complete!!!!!\")\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    if faces is():\n",
    "        return img,[]\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200,200))\n",
    "\n",
    "    return img,roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image, face = face_detector(frame)\n",
    "\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "\n",
    "        if result[1] < 500:\n",
    "            confidence = int(100*(1-(result[1])/300))\n",
    "            display_string = str(confidence)+'% Confidence it is user'\n",
    "        cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
    "\n",
    "\n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('Face Cropper', image)\n",
    "        pass\n",
    "\n",
    "    key=cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
